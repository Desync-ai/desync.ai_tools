# Desync.AI Tools

An open-source toolkit for stealthy web data extraction, boilerplate cleaning, structured storage, transformer embedding, and more â€” powered by the `desync-search` API.

---

## ğŸ”§ Features

- **Crawling & Bulk Search**: Grab web data using `DesyncClient`, with support for stealthy headful scraping.
- **Boilerplate Removal**: Strip repeated pages, headers, footers, and navbars from raw HTML or `.text_content`.
- **Data Extraction** *(WIP)*: Find emails, phones, LinkedIns, and named entities from raw text or HTML.
- **Embedding Pipelines**: Chunk, tokenize, and run transformer inference (BERT, S-BERT).
- **Link Graph Tools**: Construct internal/external page link graphs for sitemaps or network analysis.
- **Text Stats + Heuristics**: Score content quality (word count, link ratio, etc.)
- **Structured Output**: Store clean results in CSV, JSON, or SQLite.
- **Sentiment Analysis and Summarisation**: Create a concise summary and sentiment analysis on the pages you scrape.
- **Link Graph Generation**: Construct a graph on how the pages you scraped link to one another.

---

## ğŸ—‚ Directory Structure

```
DESYNC.AI_TOOLS/
â”‚
â”œâ”€â”€ basic_implementation/         # Core DesyncClient tools
â”‚   â”œâ”€â”€ bulk_search.py
â”‚   â”œâ”€â”€ crawl_search.py
â”‚   â”œâ”€â”€ stealth_search.py
â”‚   â””â”€â”€ test_search.py
â”‚
â”œâ”€â”€ data_extraction/              # Contact info extraction (email, phone, LinkedIn)
â”‚   â”œâ”€â”€ extract_contacts.py
â”‚   â”œâ”€â”€ text_summarization.py
â”‚   â”œâ”€â”€ sentiment_analyzer.py
â”‚   â””â”€â”€ named_entity_extractor.py
â”‚
â”œâ”€â”€ examples/                     # Example scripts
â”‚   â””â”€â”€ bulk_clean_and_save_csv.py
â”‚
â”œâ”€â”€ model_prep/                   # Transformer-based modeling pipeline
â”‚   â”œâ”€â”€ chunk_text_blocks.py
â”‚   â”œâ”€â”€ dataset_builder.py
â”‚   â”œâ”€â”€ tokenizer_loader.py
â”‚   â”œâ”€â”€ torch_loader.py
â”‚   â””â”€â”€ transformer_runner.py
â”‚
â”œâ”€â”€ parsers/                      # General-purpose HTML and graph tools
â”‚   â”œâ”€â”€ html_parser.py
â”‚   â”œâ”€â”€ language_detector.py
â”‚   â”œâ”€â”€ link_graph.py
â”‚   â””â”€â”€ text_stats.py
â”‚
â”œâ”€â”€ result_cleaning/              # Cleaning and deduplication
â”‚   â”œâ”€â”€ html_cleaning/
â”‚   â”‚   â””â”€â”€ remove_boilerplate_html.py
â”‚   â”œâ”€â”€ text_content_cleaning/
â”‚   â”‚    â””â”€â”€ remove_boilerplate_text.py
â”‚   â””â”€â”€ duplicate_page_remover.py
â”‚
â”œâ”€â”€ storage/                      # Save your search results
â”‚   â”œâ”€â”€ csv_storage.py
â”‚   â”œâ”€â”€ json_storage.py
â”‚   â””â”€â”€ sqlite_storage.py
â”‚
â”œâ”€â”€ output/                       # Your saved outputs (ignored by git)
â”‚
â”œâ”€â”€ .env                          # Credentials (not committed)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Install dependencies

```bash
pip install desync_search
```

```bash
pip install desync-data
```

### 2. Add your API key

Create a `.env` file in the root folder:

```
DESYNC_API_KEY=your_api_key_here
```

### 3. Run an example

```bash
python examples/bulk_clean_and_save_csv.py
```

---

## ğŸ“¦ Storage Formats

| Format | Path                | Notes                              |
|--------|---------------------|------------------------------------|
| CSV    | `storage/csv/`      | For spreadsheets, Pandas, Excel    |
| JSON   | `storage/json/`     | Human-readable + flexible          |
| SQLite | `storage/sqlite/`   | Lightweight relational database    |

---

## ğŸ‘¨â€ğŸ’» Authors

- Jackson Ballow  
- Mark Evgenev  
- Maks Kubicki

---

## ğŸªª License

MIT â€” use freely, improve freely, and credit where due.
